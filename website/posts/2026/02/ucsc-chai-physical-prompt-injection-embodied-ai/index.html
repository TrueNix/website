<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="google-adsense-account" content="ca-pub-9044791241492233">
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>UCSC / The Register — CHAI: physical prompt injection hijacks self-driving cars and drones via road signs — al-ice.ai</title>
  <meta name="description" content="UCSC researchers demonstrate CHAI, a physical-world indirect prompt injection attack that uses printed road signs to hijack vision-language models driving autonomous vehicles and drones." />
  <link rel="canonical" href="https://al-ice.ai/posts/2026/02/ucsc-chai-physical-prompt-injection-embodied-ai/" />
  <meta name="robots" content="index,follow" />
  <meta name="post:title" content="UCSC / The Register — CHAI: physical prompt injection hijacks self-driving cars and drones via road signs" />
  <meta name="post:date" content="2026-02-03" />
  <meta name="post:category" content="research" />
  <meta name="post:categoryLabel" content="Research" />

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZX0TZSMV99"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-ZX0TZSMV99');
  </script>

  <link rel="stylesheet" href="/assets/css/site.css" />
  <script>(function(){try{var t=localStorage.getItem('theme');if(t==="retro")document.documentElement.setAttribute('data-theme','retro');}catch(e){}})();</script>
</head>
<body>
  <div class="wrap">
    <header class="site">
      <div class="brand"><a href="/">al-ice.ai</a></div>
      <nav class="small">
        <a href="/posts/">Posts</a>
        <a href="/categories/">Categories</a>
        <a href="/search/">Search</a>
        <button id="themeToggle" class="theme-toggle" type="button" aria-label="Toggle CRT mode"></button>
</nav>
    </header>
    <main>
      <article class="post">
        <h1 class="post-title">UCSC / The Register — CHAI: physical prompt injection hijacks self-driving cars and drones via road signs</h1>
        <div class="post-meta">
          <time datetime="2026-02-03">2026-02-03</time>
          <a class="badge" href="/categories/research/">Research</a>
        </div>

        <ul>
          <li>Researchers at UC Santa Cruz and Johns Hopkins introduce <strong>CHAI (Command Hijacking against embodied AI)</strong>, a new class of <strong>environmental indirect prompt injection</strong> that uses printed signs in the physical world to hijack AI-powered vehicles and drones.</li>
          <li><strong>How it works:</strong> text-based commands (e.g., "proceed", "turn left") are displayed on signs placed in the camera's field of view. The large vision-language model (LVLM) driving the system interprets the sign text as an instruction, overriding its actual mission.</li>
          <li>The team used AI to optimize both the <strong>prompt wording</strong> and the sign's visual properties (font, color, placement) to maximize the probability of the LVLM obeying the injected command.</li>
          <li><strong>Self-driving car tests:</strong> 81.8% success rate. Using the DriveLM dataset, CHAI tricked LVLMs into turning left at a crosswalk where pedestrians were present — overriding the correct "slow down" decision.</li>
          <li><strong>Drone tracking tests:</strong> up to 95.5% success rate. CloudTrack was fooled into misidentifying a generic car as a police vehicle by simply displaying "Police Santa Cruz" on the car's roof.</li>
          <li>Attacks worked across <strong>multiple languages</strong> (English, Chinese, Spanish, Spanglish) and against both closed (GPT-4o) and open (InternVL) models.</li>
          <li>Physical-world validation confirmed results: RC cars in real corridors obeyed injected commands at rates comparable to simulation.</li>
          <li>Green backgrounds with yellow text were the most effective sign design across all tested languages.</li>
        </ul>

        <h2>Why it matters</h2>
        <ul>
          <li>This takes prompt injection <strong>out of chatbots and into the physical world</strong>. Embodied AI systems — autonomous vehicles, delivery drones, security robots — are now demonstrated targets for environmental manipulation.</li>
          <li>Unlike adversarial image patches (which exploit vision model weights), CHAI exploits the <strong>language understanding layer</strong>, meaning any LVLM-powered system that reads its environment is potentially vulnerable.</li>
          <li>No digital access needed: the attacker just prints a sign. This has implications for <strong>physical security of autonomous systems</strong> in public spaces.</li>
        </ul>

        <h2>What to do</h2>
        <ul>
          <li><strong>Don't trust visual text as commands:</strong> embodied AI systems should treat OCR-extracted text from the environment as untrusted input, not instructions.</li>
          <li><strong>Implement input separation:</strong> architect LVLM pipelines so that environmental observations and system commands flow through distinct channels that cannot be confused.</li>
          <li><strong>Test against environmental injection:</strong> red-team autonomous systems with physical-world prompt injection scenarios before deployment.</li>
          <li><strong>Monitor for anomalous behavior:</strong> runtime anomaly detection that flags sudden decision changes (e.g., "turn" when "stop" was expected) can catch injection attempts.</li>
        </ul>

        <h2>Sources</h2>
        <ul>
          <li><a href="https://www.theregister.com/2026/01/30/road_sign_hijack_ai?utm_source=al-ice.ai&utm_medium=referral&utm_campaign=posts" target="_blank" rel="noopener">The Register — Autonomous cars, drones cheerfully obey prompt injection by road sign</a></li>
          <li><a href="https://news.ucsc.edu/2026/01/misleading-text-can-hijack-ai-enabled-robots/?utm_source=al-ice.ai&utm_medium=referral&utm_campaign=posts" target="_blank" rel="noopener">UC Santa Cruz — Misleading text in the physical world can hijack AI-enabled robots</a></li>
          <li><a href="https://arxiv.org/abs/2504.13201?utm_source=al-ice.ai&utm_medium=referral&utm_campaign=posts" target="_blank" rel="noopener">Related: CEE — inference-time jailbreak defense for embodied intelligence (arXiv)</a></li>
        </ul>

      </article>
    </main>

    <footer class="small muted">
      <div><a href="/posts/">← All posts</a> • <a href="/sitemap.xml">Sitemap</a></div>
    </footer>
  </div>
  <script>(function(){
      var btn=document.getElementById('themeToggle');
      if(!btn) return;

      function isRetro(){ return document.documentElement.getAttribute('data-theme')==='retro'; }

      function crtIcon(){
        // Animated CRT icon (gif)
        return '<img class="theme-ico" src="/assets/img/crt.gif" alt="" aria-hidden="true" />';
      }

      function flatIcon(){
        return '<svg class="theme-ico" viewBox="0 0 24 24" aria-hidden="true"><path fill="currentColor" d="M4 6a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v9a2 2 0 0 1-2 2h-5l1 2H8l1-2H6a2 2 0 0 1-2-2V6Zm2 0v9h12V6H6Z"/></svg>';
      }

      function render(){
        if(isRetro()){
          btn.classList.add('is-retro');
          btn.innerHTML = '<span class="theme-screen">' + flatIcon() + '<span class="crt-noise" aria-hidden="true"></span><span class="crt-line" aria-hidden="true"></span></span><span class="theme-label">Modern</span>';
          btn.setAttribute('title','Switch to modern');
          btn.setAttribute('aria-label','Switch to modern');
        }else{
          btn.classList.remove('is-retro');
          btn.innerHTML = '<span class="theme-screen">' + crtIcon() + '<span class="crt-noise" aria-hidden="true"></span><span class="crt-line" aria-hidden="true"></span></span><span class="theme-label">CRT</span>';
          btn.setAttribute('title','Toggle CRT (80/90s) vibe');
          btn.setAttribute('aria-label','Toggle CRT (80/90s) vibe');
        }
      }

      function pulse(anim){
        try{
          btn.classList.remove('anim-connect','anim-disconnect');
          // force reflow so the animation re-triggers
          void btn.offsetWidth;
          btn.classList.add(anim);
          window.setTimeout(function(){ btn.classList.remove(anim); }, 700);
        }catch(e){}
      }

      function setRetro(on){
        if(on){
          pulse('anim-connect');
          document.documentElement.setAttribute('data-theme','retro');
          try{ localStorage.setItem('theme','retro'); }catch(e){}
        }else{
          pulse('anim-disconnect');
          document.documentElement.removeAttribute('data-theme');
          try{ localStorage.removeItem('theme'); }catch(e){}
        }
        render();
      }

      render();
      btn.addEventListener('click', function(){ setRetro(!isRetro()); });
    })();</script>
</body>
</html>
