<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="google-adsense-account" content="ca-pub-9044791241492233">
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>arXiv — Systematic Review of LLM Defenses Against Prompt Injection: Expanding NIST Taxonomy</title>
  <meta name="description" content="First systematic literature review covering 88 studies on prompt injection and jailbreak defenses for LLMs, extending NIST's adversarial ML taxonomy with new defense categories and a practical catalog." />
  <link rel="canonical" href="https://al-ice.ai/posts/2026/02/arxiv-slr-prompt-injection-defenses-nist-taxonomy/" />
  <meta name="robots" content="index,follow" />
  <meta name="post:title" content="arXiv — Systematic Review of LLM Defenses Against Prompt Injection: Expanding NIST Taxonomy" />
  <meta name="post:date" content="2026-02-05" />
  <meta name="post:category" content="research" />
  <meta name="post:categoryLabel" content="Research" />

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZX0TZSMV99"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-ZX0TZSMV99');
  </script>

  <link rel="stylesheet" href="/assets/css/site.css" />
  <script>(function(){try{var t=localStorage.getItem('theme');if(t==="retro")document.documentElement.setAttribute('data-theme','retro');}catch(e){}})();</script>
</head>
<body>
  <div class="wrap">
    <header class="site">
      <div class="brand"><a href="/">al-ice.ai</a></div>
      <nav class="small">
        <a href="/posts/">Posts</a>
        <a href="/categories/">Categories</a>
        <a href="/search/">Search</a>
        <button id="themeToggle" class="theme-toggle" type="button" aria-label="Toggle CRT mode"></button>
</nav>
    </header>
    <main>
      <article class="post">
        <h1 class="post-title">arXiv — Systematic Review of LLM Defenses Against Prompt Injection: Expanding NIST Taxonomy</h1>
        <div class="post-meta">
          <time datetime="2026-02-05">2026-02-05</time>
          <a class="badge" href="/categories/research/">Research</a>
        </div>

        <ul>
          <li>Barcha Correia et al. present the <strong>first systematic literature review (SLR)</strong> specifically focused on prompt injection and jailbreak mitigation strategies for LLMs, covering <strong>88 studies</strong>.</li>
          <li>The paper builds on <strong>NIST's adversarial machine learning report</strong> (AI 100-2e2025), extending its taxonomy with additional defense categories not previously documented.</li>
          <li>Key contribution: a <strong>comprehensive catalog</strong> of all 88 reviewed defenses, documenting quantitative effectiveness across specific LLMs and attack datasets, plus flags for open-source availability and model-agnostic applicability.</li>
          <li>Defense categories covered span <strong>input filtering, output filtering, prompt engineering, fine-tuning, ensemble methods, probing-based detection</strong>, and more—each mapped to NIST's standardised terminology.</li>
          <li>The review identifies studies <strong>beyond those in NIST's report</strong> and other existing surveys, filling gaps in the evolving landscape of prompt injection countermeasures.</li>
          <li>Practical focus: the catalog is designed as a <strong>reference for developers</strong> building production systems, not just for academic researchers—each defense includes implementation notes and reported metrics.</li>
          <li>Submitted to <strong>Elsevier Computer Science Review</strong>; 27 pages, 14 figures, 11 tables.</li>
        </ul>

        <h2>Why it matters</h2>
        <ul>
          <li>Prompt injection remains the <strong>#1 unsolved security problem</strong> for LLM-based applications. Having a structured, NIST-aligned taxonomy of defenses helps practitioners choose and layer mitigations systematically rather than ad hoc.</li>
          <li>The catalog of 88 defenses with <strong>comparable effectiveness metrics</strong> is immediately useful for security teams evaluating which safeguards to deploy.</li>
          <li>By adopting NIST terminology, the work enables <strong>consistent cross-study comparison</strong>—a prerequisite for the field maturing from scattered one-off fixes to engineering discipline.</li>
        </ul>

        <h2>What to do</h2>
        <ul>
          <li><strong>Use the catalog:</strong> If you're deploying LLM-based features, review the paper's defense matrix to identify which mitigations apply to your architecture and threat model.</li>
          <li><strong>Layer defenses:</strong> No single technique is sufficient. The SLR reinforces that effective protection requires combining input/output filtering, prompt hardening, and runtime monitoring.</li>
          <li><strong>Track NIST updates:</strong> The extended taxonomy provides a living framework—watch for future NIST revisions that may incorporate these additions.</li>
          <li><strong>Benchmark before shipping:</strong> Use the reported attack datasets and success rates as baselines to test your own defenses before production deployment.</li>
        </ul>

        <h2>Sources</h2>
        <ul>
          <li><a href="https://arxiv.org/abs/2601.22240?utm_source=al-ice.ai&utm_medium=referral&utm_campaign=posts">arXiv: A Systematic Literature Review on LLM Defenses Against Prompt Injection and Jailbreaking (2601.22240)</a></li>
          <li><a href="https://csrc.nist.gov/pubs/ai/100/2/e2025/final?utm_source=al-ice.ai&utm_medium=referral&utm_campaign=posts">NIST AI 100-2e2025: Adversarial Machine Learning</a></li>
        </ul>
      </article>
    </main>
    <footer class="small muted">
      <div>© 2026 al-ice.ai • <a href="/sitemap.xml">Sitemap</a></div>
    </footer>
  </div>
  <script>(function(){
      var btn=document.getElementById('themeToggle');
      if(!btn) return;

      function isRetro(){ return document.documentElement.getAttribute('data-theme')==='retro'; }

      function crtIcon(){
        // Animated CRT icon (gif)
        return '<img class="theme-ico" src="/assets/img/crt.gif" alt="" aria-hidden="true" />';
      }

      function flatIcon(){
        return '<svg class="theme-ico" viewBox="0 0 24 24" aria-hidden="true"><path fill="currentColor" d="M4 6a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v9a2 2 0 0 1-2 2h-5l1 2H8l1-2H6a2 2 0 0 1-2-2V6Zm2 0v9h12V6H6Z"/></svg>';
      }

      function render(){
        if(isRetro()){
          btn.classList.add('is-retro');
          btn.innerHTML = '<span class="theme-screen">' + flatIcon() + '<span class="crt-noise" aria-hidden="true"></span><span class="crt-line" aria-hidden="true"></span></span><span class="theme-label">Modern</span>';
          btn.setAttribute('title','Switch to modern');
          btn.setAttribute('aria-label','Switch to modern');
        }else{
          btn.classList.remove('is-retro');
          btn.innerHTML = '<span class="theme-screen">' + crtIcon() + '<span class="crt-noise" aria-hidden="true"></span><span class="crt-line" aria-hidden="true"></span></span><span class="theme-label">CRT</span>';
          btn.setAttribute('title','Toggle CRT (80/90s) vibe');
          btn.setAttribute('aria-label','Toggle CRT (80/90s) vibe');
        }
      }

      function pulse(anim){
        try{
          btn.classList.remove('anim-connect','anim-disconnect');
          // force reflow so the animation re-triggers
          void btn.offsetWidth;
          btn.classList.add(anim);
          window.setTimeout(function(){ btn.classList.remove(anim); }, 700);
        }catch(e){}
      }

      function setRetro(on){
        if(on){
          pulse('anim-connect');
          document.documentElement.setAttribute('data-theme','retro');
          try{ localStorage.setItem('theme','retro'); }catch(e){}
        }else{
          pulse('anim-disconnect');
          document.documentElement.removeAttribute('data-theme');
          try{ localStorage.removeItem('theme'); }catch(e){}
        }
        render();
      }

      render();
      btn.addEventListener('click', function(){ setRetro(!isRetro()); });
    })();</script>
</body>
</html>
